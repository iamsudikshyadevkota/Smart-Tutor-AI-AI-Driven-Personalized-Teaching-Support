{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial** **for** **Web scrapping using ChatGPT**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5NJbV034pVCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt:**\n",
        "\n",
        "Act like an senior webscrapper.I want to scrape university of north texas library API to find some articles. what are the details you need to start scraping.\n",
        "\n",
        "**GPT Response**:\n",
        "\n",
        "Deliverables to Start\n",
        "To kick off the project, I would need:\n",
        "\n",
        "API documentation URL or a sample request/response from the library API.\n",
        "Your preferred programming language (assume Python here).\n",
        "A few example searches or data youâ€™d like to retrieve (e.g., \"library resources on AI\").\n",
        "Desired output format for the tutorial (console printout, CSV, etc.).\n",
        "Let me know if you'd like me to help design the code template or structure for this! ðŸ˜Š"
      ],
      "metadata": {
        "id": "joT9w04IpRGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`Here, I am have intiated conversation with chatGPT, because I was not aware how can should I get access to Library API.`*"
      ],
      "metadata": {
        "id": "2i5bSAWvmkuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt: ***\n",
        "Here is the API documentation url :https://digital.library.unt.edu/api/\n",
        "\n",
        "***Response: ***\n",
        "1. **Explore the API Documentation**\n",
        "Open the documentation at UNT Digital Library API and look for:\n",
        "\n",
        "Base URL: The root endpoint for making API requests.\n",
        "Endpoints: Identify the specific ones for fetching articles or metadata. Common endpoints might include:\n",
        "Search (/search)\n",
        "Items (/items)\n",
        "Collections (/collections)\n",
        "Parameters: Check query parameters like\n",
        "Keywords for search\n",
        "Filtering options (e.g., author, date, type of publication)\n",
        "Sorting options\n",
        "Pagination controls\n",
        "Response Format: Typically JSON or XML. Look for response examples to understand the structure.\n",
        "2. Authentication\n",
        "Check if the API requires an API key or token. If not, itâ€™s straightforward; otherwise:\n",
        "\n",
        "Sign up to get an API key (if needed).\n",
        "Familiarize yourself with how to send it (via headers or query parameters).\n",
        "3. Test the API\n",
        "Use tools like Postman or Pythonâ€™s requests library to test the API. For example:\n",
        "\n",
        "bash\n",
        "Copy\n",
        "Edit\n",
        "curl \"https://digital.library.unt.edu/api/v1/search/?q=machine+learning\"\n",
        "4. Draft Tutorial Workflow\n",
        "Hereâ€™s how you can organize the tutorial for API-based web scraping:"
      ],
      "metadata": {
        "id": "uXCYG9jJpSZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`**After reviewing the response, I found some useful resources that could be helpful. I then shared them with ChatGPT for further guidance on the next steps**.`"
      ],
      "metadata": {
        "id": "K9hB0hxom9zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt:** this is the one which has .\n",
        "https://digital.library.unt.edu/search/opensearch/\n",
        "\n",
        "\n",
        "**Response**:\n",
        "Thank you for clarifying! The OpenSearch endpoint at https://digital.library.unt.edu/search/opensearch/ follows the OpenSearch protocol, which typically returns XML or JSON for search queries. Here's how we can create the tutorial based on this specific API endpoint:\n",
        "\n",
        "Step 1: Understand the OpenSearch API\n",
        "Visit OpenSearch Documentation:\n",
        "\n",
        "Base URL: https://digital.library.unt.edu/search/opensearch/\n",
        "Query Parameters:\n",
        "q: Search term (e.g., q=machine+learning).\n",
        "type: Specify the type of content (e.g., articles, theses, reports).\n",
        "fq[]: Filters (e.g., dates, language, collection).\n",
        "start: The index of the first result (for pagination).\n",
        "rows: Number of results per page (e.g., rows=10).\n",
        "Response Format: Typically XML.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u3prEcJXmXms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`***Here, I learned about the base URL and API endpoints. Additionally, I learn about query parameters which are useful for enabling multi-term searches.***`"
      ],
      "metadata": {
        "id": "b8wn7JJuncd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests xmltodict pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqVj7-TBnXqC",
        "outputId": "e4cd27f4-0a21-4d67-e7b4-061bef7765b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://digital.library.unt.edu/search/opensearch/\"\n",
        "\n",
        "# Query parameters\n",
        "params = {\n",
        "    \"q\": \"machine learning\",  # Search term\n",
        "    \"type\": \"article\",        # Filter by type\n",
        "    \"start\": 0,               # Start index for pagination\n",
        "    \"rows\": 10                # Number of results per page\n",
        "}\n",
        "\n",
        "# Make the request\n",
        "response = requests.get(base_url, params=params)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    print(response.text)  # Print XML response\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t821rLfwnY96",
        "outputId": "374906f7-d354-4a54-c82f-b3c3eeb574e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
            "  <head profile=\"http://a9.com/-/spec/opensearch/1.1/\">\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\"/>\n",
            "    <title>UNT Digital Library</title>\n",
            "    <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"https://digital.library.unt.edu/search/opensearch/document/\" title=\"UNT Digital Library\"/>\n",
            "    <link rel=\"alternate\" type=\"application/atom+xml\" href=\"https://digital.library.unt.edu/search/opensearch/?q=machine learning&amp;pw=1&amp;format=atom\"/>\n",
            "    <meta name=\"totalResults\" content=\"18095\"/>\n",
            "    <meta name=\"startIndex\" content=\"1\"/>\n",
            "    <meta name=\"itemsPerPage\" content=\"10\"/>\n",
            "  </head>\n",
            "  <body>\n",
            "    <ul>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944346/\">Machine Learning in Computational Chemistry</a>\n",
            "        <div>Machine learning and artificial intelligence are increasingly becoming mainstream in our daily lives, from smart algorithms that recognize us online to cars that can drive themselves.  In this defense, the intersection of machine learning and computational chemistry are applied to the generation of new PFAS molecules that are less toxic than those currently used today without sacrificing the unique properties that make them desirable for industrial use.  Additionally, machine learning is used to complete the SAMPL6 logP challenge and to correlate molecules to best DFT functionals for enthalpies of formation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1703277/\">Privacy Preserving Machine Learning as a Service</a>\n",
            "        <div>Machine learning algorithms based on neural networks have achieved remarkable results and are being extensively used in different domains. However, the machine learning algorithms requires access to raw data which is often privacy sensitive. To address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. In this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. We focus on training and classification of the well-known neural networks and convolutional neural networks. First, we design methods for approximation of the activation functions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. Then, we train neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. Finally, we implement neural networks and convolutional neural networks over encrypted data and measure performance of the models.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc278720/\">A Machine Learning Method Suitable for Dynamic Domains</a>\n",
            "        <div>The efficacy of a machine learning technique is domain dependent. Some machine learning techniques work very well for certain domains but are ill-suited for other domains. One area that is of real-world concern is the flexibility with which machine learning techniques can adapt to dynamic domains. Currently, there are no known reports of any system that can learn dynamic domains, short of starting over (i.e., re-running the program). Starting over is neither time nor cost efficient for real-world production environments. This dissertation studied a method, referred to as Experience Based Learning (EBL), that attempts to deal with conditions related to learning dynamic domains. EBL is an extension of Instance Based Learning methods. The hypothesis of the study related to this research was that the EBL method would automatically adjust to domain changes and still provide classification accuracy similar to methods that require starting over. To test this hypothesis, twelve widely studied machine learning datasets were used. A dynamic domain was simulated by presenting these datasets in an uninterrupted cycle of train, test, and retrain. The order of the twelve datasets and the order of records within each dataset were randomized to control for order biases in each of ten runs. As a result, these methods provided datasets that represent extreme levels of domain change. Using the above datasets, EBL's mean classification accuracies for each dataset were compared to the published static domain results of other machine learning systems. The results indicated that the EBL's system performance was not statistically different (p&gt;0.30) from the other machine learning methods. These results indicate that the EBL system is able to adjust to an extreme level of domain change and yet produce satisfactory results. This finding supports the use of the EBL method in real-world environments that incur rapid changes to both variables and values.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc993374/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>This paper explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc990997/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>Poster presented at the 2017 ACM/IEEE-CS Joint Conference on Digital Libraries. explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289519/\">Enterprise Use of Artificial Intelligence and Machine Learning</a>\n",
            "        <div>The objective of this report was to provide information on risks associated with Enterprise use of artificial intelligence and machine learning. The authors reviewed internal FHFA and Enterprise documents, as well as publicly available documents.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289499/\">Artificial Intelligence and Machine Learning In Consumer Products</a>\n",
            "        <div>This report provides background information on artificial intelligence and machine learning (AI/ML) and outlines a proposed framework to evaluate the safety of these technologies in consumer products. It outlines efforts underway and recommended future actions the CPSC can take to identify safety concerns with AI/ML technologies.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944318/\">Data Quality Evaluation and Improvement for Machine Learning</a>\n",
            "        <div>In this research the focus is on data-centric AI with a specific concentration on data quality evaluation and improvement for machine learning. We first present a practical framework for data quality evaluation and improvement, using a legal domain as a case study and build a corpus for legal argument mining. We first created an initial corpus with 4,937 instances that were manually labeled. We define five data quality evaluation dimensions: comprehensiveness, correctness, variety, class imbalance, and duplication, and conducted a quantitative evaluation on these dimensions for the legal dataset and two existing datasets in the medical domain for medical concept normalization. The first group of experiments showed that class imbalance and insufficient training data are the two major data quality issues that negatively impacted the quality of the system that was built on the legal corpus. The second group of experiments showed that the overlap between the test datasets and the training datasets, which we defined as \"duplication,\" is the major data quality issue for the two medical corpora. We explore several widely used machine learning methods for data quality improvement. Compared to pseudo-labeling, co-training, and expectation-maximization (EM), generative adversarial network (GAN) is more effective for automated data augmentation, especially when a small portion of labeled data and a large amount of unlabeled data is available. The data validation process, the performance improvement strategy, and the machine learning framework for data evaluation and improvement discussed in this dissertation can be used by machine learning researchers and practitioners to build high-performance machine learning systems. All the materials including the data, code, and results will be released at: https://github.com/haihua0913/dissertation-dqei.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1011752/\">Developing a Phylogeny Based Machine Learning Algorithm for Metagenomics</a>\n",
            "        <div>Metagenomics is the study of the totality of the complete genetic elements discovered from a defined environment. Different from traditional microbiology study, which only analyzes a small percent of microbes that could survive in laboratory, metagenomics allows researchers to get entire genetic information from all the samples in the communities. So metagenomics enables understanding of the target environments and the hidden relationships between bacteria and diseases. In order to efficiently analyze the metagenomics data, cutting-edge technologies for analyzing the relationships among microbes and communities are required. To overcome the challenges brought by rapid growth in metagenomics datasets, advances in novel methodologies for interpreting metagenomics data are clearly needed.\n",
            "The first two chapters of this dissertation summarize and compare the widely-used methods in metagenomics and integrate these methods into pipelines. Properly analyzing metagenomics data requires a variety of bioinformatcis and statistical approaches to deal with different situations. The raw reads from sequencing centers need to be processed and denoised by several steps and then be further interpreted by ecological and statistical analysis. So understanding these algorithms and combining different approaches could potentially reduce the influence of noises and biases at different steps. And an efficient and accurate pipeline is important to robustly decipher the differences and functionality of bacteria in communities.\n",
            "Traditional statistical analysis and machine learning algorithms have their limitations on analyzing metagenomics data. Thus, rest three chapters describe a new phylogeny based machine learning and feature selection algorithm to overcome these problems. The new method outperforms traditional algorithms and can provide more robust candidate microbes for further analysis. With the frowing sample size, deep neural network could potentially describe more complicated characteristic of data and thus improve model accuracy. So a deep learning framework is designed on top of the shallow learning algorithm stated above in order to further improve the prediction and selection accuracy.\n",
            "The present dissertation work provides a powerful tool that utilizes machine learning techniques to identify signature bacteria and key information from huge amount of metagenomics data.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc897226/\">Coordinated machine learning and decision support for situation awareness.</a>\n",
            "        <div>For applications such as force protection, an effective decision maker needs to maintain an unambiguous grasp of the environment. Opportunities exist to leverage computational mechanisms for the adaptive fusion of diverse information sources. The current research employs neural networks and Markov chains to process information from sources including sensors, weather data, and law enforcement. Furthermore, the system operator's input is used as a point of reference for the machine learning algorithms. More detailed features of the approach are provided, along with an example force protection scenario.</div>\n",
            "      </li>\n",
            "    </ul>\n",
            "  </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`From here, GPT made an incorrect assumption, expecting the output to be in XML, while it was actually in HTML. This led to an error, so I began debugging the code.`***"
      ],
      "metadata": {
        "id": "aJuricqyoAoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xmltodict\n",
        "\n",
        "# Parse the XML response\n",
        "data = xmltodict.parse(response.text)\n",
        "\n",
        "# Extract relevant details\n",
        "channel = data[\"rss\"][\"channel\"]  # OpenSearch typically uses RSS format\n",
        "items = channel.get(\"item\", [])  # Each search result is in the \"item\" tag\n",
        "\n",
        "# Print results\n",
        "for item in items:\n",
        "    print(f\"Title: {item['title']}\")\n",
        "    print(f\"Link: {item['link']}\")\n",
        "    print(f\"Description: {item.get('description', 'No description')}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "sJ0Iya8NnbYj",
        "outputId": "6fb08917-3cd4-4c09-a8d3-648f8f1660f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'rss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-41c3f56ac8f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract relevant details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channel\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# OpenSearch typically uses RSS format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"item\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Each search result is in the \"item\" tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'rss'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt: ** KeyError                                  Traceback (most recent call last)\n",
        "<ipython-input-3-41c3f56ac8f3> in <cell line: 0>()\n",
        "      5\n",
        "      6 # Extract relevant details\n",
        "----> 7 channel = data[\"rss\"][\"channel\"]  # OpenSearch typically uses RSS format\n",
        "      8 items = channel.get(\"item\", [])  # Each search result is in the \"item\" tag\n",
        "      9\n",
        "\n",
        "KeyError: 'rss'   \n",
        "\n",
        "\n",
        "**Response:**\n",
        "The KeyError: 'rss' suggests that the API response does not include the expected rss tag. This is likely because the structure of the response is different than assumed. Letâ€™s debug and resolve this issue step by step:"
      ],
      "metadata": {
        "id": "3YShps3bn3yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''First, check what the API actually returns. Modify the code to print the raw response:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "print(response.text)  # Print the raw XML response\n",
        "Look at the structure of the response. For example:\n",
        "\n",
        "Does it start with <rss>?\n",
        "Does it have other tags like <feed> or <response>? '''\n",
        "\n",
        "print(response.text)  # Print the raw XML response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBeTjmvhnpPA",
        "outputId": "b4bfdb14-88ee-404f-eca8-c49cdf434e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
            "  <head profile=\"http://a9.com/-/spec/opensearch/1.1/\">\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\"/>\n",
            "    <title>UNT Digital Library</title>\n",
            "    <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"https://digital.library.unt.edu/search/opensearch/document/\" title=\"UNT Digital Library\"/>\n",
            "    <link rel=\"alternate\" type=\"application/atom+xml\" href=\"https://digital.library.unt.edu/search/opensearch/?q=machine learning&amp;pw=1&amp;format=atom\"/>\n",
            "    <meta name=\"totalResults\" content=\"18095\"/>\n",
            "    <meta name=\"startIndex\" content=\"1\"/>\n",
            "    <meta name=\"itemsPerPage\" content=\"10\"/>\n",
            "  </head>\n",
            "  <body>\n",
            "    <ul>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944346/\">Machine Learning in Computational Chemistry</a>\n",
            "        <div>Machine learning and artificial intelligence are increasingly becoming mainstream in our daily lives, from smart algorithms that recognize us online to cars that can drive themselves.  In this defense, the intersection of machine learning and computational chemistry are applied to the generation of new PFAS molecules that are less toxic than those currently used today without sacrificing the unique properties that make them desirable for industrial use.  Additionally, machine learning is used to complete the SAMPL6 logP challenge and to correlate molecules to best DFT functionals for enthalpies of formation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1703277/\">Privacy Preserving Machine Learning as a Service</a>\n",
            "        <div>Machine learning algorithms based on neural networks have achieved remarkable results and are being extensively used in different domains. However, the machine learning algorithms requires access to raw data which is often privacy sensitive. To address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. In this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. We focus on training and classification of the well-known neural networks and convolutional neural networks. First, we design methods for approximation of the activation functions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. Then, we train neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. Finally, we implement neural networks and convolutional neural networks over encrypted data and measure performance of the models.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc278720/\">A Machine Learning Method Suitable for Dynamic Domains</a>\n",
            "        <div>The efficacy of a machine learning technique is domain dependent. Some machine learning techniques work very well for certain domains but are ill-suited for other domains. One area that is of real-world concern is the flexibility with which machine learning techniques can adapt to dynamic domains. Currently, there are no known reports of any system that can learn dynamic domains, short of starting over (i.e., re-running the program). Starting over is neither time nor cost efficient for real-world production environments. This dissertation studied a method, referred to as Experience Based Learning (EBL), that attempts to deal with conditions related to learning dynamic domains. EBL is an extension of Instance Based Learning methods. The hypothesis of the study related to this research was that the EBL method would automatically adjust to domain changes and still provide classification accuracy similar to methods that require starting over. To test this hypothesis, twelve widely studied machine learning datasets were used. A dynamic domain was simulated by presenting these datasets in an uninterrupted cycle of train, test, and retrain. The order of the twelve datasets and the order of records within each dataset were randomized to control for order biases in each of ten runs. As a result, these methods provided datasets that represent extreme levels of domain change. Using the above datasets, EBL's mean classification accuracies for each dataset were compared to the published static domain results of other machine learning systems. The results indicated that the EBL's system performance was not statistically different (p&gt;0.30) from the other machine learning methods. These results indicate that the EBL system is able to adjust to an extreme level of domain change and yet produce satisfactory results. This finding supports the use of the EBL method in real-world environments that incur rapid changes to both variables and values.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc993374/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>This paper explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc990997/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>Poster presented at the 2017 ACM/IEEE-CS Joint Conference on Digital Libraries. explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289519/\">Enterprise Use of Artificial Intelligence and Machine Learning</a>\n",
            "        <div>The objective of this report was to provide information on risks associated with Enterprise use of artificial intelligence and machine learning. The authors reviewed internal FHFA and Enterprise documents, as well as publicly available documents.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289499/\">Artificial Intelligence and Machine Learning In Consumer Products</a>\n",
            "        <div>This report provides background information on artificial intelligence and machine learning (AI/ML) and outlines a proposed framework to evaluate the safety of these technologies in consumer products. It outlines efforts underway and recommended future actions the CPSC can take to identify safety concerns with AI/ML technologies.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944318/\">Data Quality Evaluation and Improvement for Machine Learning</a>\n",
            "        <div>In this research the focus is on data-centric AI with a specific concentration on data quality evaluation and improvement for machine learning. We first present a practical framework for data quality evaluation and improvement, using a legal domain as a case study and build a corpus for legal argument mining. We first created an initial corpus with 4,937 instances that were manually labeled. We define five data quality evaluation dimensions: comprehensiveness, correctness, variety, class imbalance, and duplication, and conducted a quantitative evaluation on these dimensions for the legal dataset and two existing datasets in the medical domain for medical concept normalization. The first group of experiments showed that class imbalance and insufficient training data are the two major data quality issues that negatively impacted the quality of the system that was built on the legal corpus. The second group of experiments showed that the overlap between the test datasets and the training datasets, which we defined as \"duplication,\" is the major data quality issue for the two medical corpora. We explore several widely used machine learning methods for data quality improvement. Compared to pseudo-labeling, co-training, and expectation-maximization (EM), generative adversarial network (GAN) is more effective for automated data augmentation, especially when a small portion of labeled data and a large amount of unlabeled data is available. The data validation process, the performance improvement strategy, and the machine learning framework for data evaluation and improvement discussed in this dissertation can be used by machine learning researchers and practitioners to build high-performance machine learning systems. All the materials including the data, code, and results will be released at: https://github.com/haihua0913/dissertation-dqei.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1011752/\">Developing a Phylogeny Based Machine Learning Algorithm for Metagenomics</a>\n",
            "        <div>Metagenomics is the study of the totality of the complete genetic elements discovered from a defined environment. Different from traditional microbiology study, which only analyzes a small percent of microbes that could survive in laboratory, metagenomics allows researchers to get entire genetic information from all the samples in the communities. So metagenomics enables understanding of the target environments and the hidden relationships between bacteria and diseases. In order to efficiently analyze the metagenomics data, cutting-edge technologies for analyzing the relationships among microbes and communities are required. To overcome the challenges brought by rapid growth in metagenomics datasets, advances in novel methodologies for interpreting metagenomics data are clearly needed.\n",
            "The first two chapters of this dissertation summarize and compare the widely-used methods in metagenomics and integrate these methods into pipelines. Properly analyzing metagenomics data requires a variety of bioinformatcis and statistical approaches to deal with different situations. The raw reads from sequencing centers need to be processed and denoised by several steps and then be further interpreted by ecological and statistical analysis. So understanding these algorithms and combining different approaches could potentially reduce the influence of noises and biases at different steps. And an efficient and accurate pipeline is important to robustly decipher the differences and functionality of bacteria in communities.\n",
            "Traditional statistical analysis and machine learning algorithms have their limitations on analyzing metagenomics data. Thus, rest three chapters describe a new phylogeny based machine learning and feature selection algorithm to overcome these problems. The new method outperforms traditional algorithms and can provide more robust candidate microbes for further analysis. With the frowing sample size, deep neural network could potentially describe more complicated characteristic of data and thus improve model accuracy. So a deep learning framework is designed on top of the shallow learning algorithm stated above in order to further improve the prediction and selection accuracy.\n",
            "The present dissertation work provides a powerful tool that utilizes machine learning techniques to identify signature bacteria and key information from huge amount of metagenomics data.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc897226/\">Coordinated machine learning and decision support for situation awareness.</a>\n",
            "        <div>For applications such as force protection, an effective decision maker needs to maintain an unambiguous grasp of the environment. Opportunities exist to leverage computational mechanisms for the adaptive fusion of diverse information sources. The current research employs neural networks and Markov chains to process information from sources including sensors, weather data, and law enforcement. Furthermore, the system operator's input is used as a point of reference for the machine learning algorithms. More detailed features of the approach are provided, along with an example force protection scenario.</div>\n",
            "      </li>\n",
            "    </ul>\n",
            "  </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here is an example of wrong prompts.**\n",
        "**Which you should not folow**"
      ],
      "metadata": {
        "id": "7fner7lslzZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt** : <html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
        "  <head profile=\"http://a9.com/-/spec/opensearch/1.1/\">\n",
        "    <meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\"/>\n",
        "    <title\n",
        "the starting is not with <rss>\n",
        "\n",
        "Rsponse:\n",
        "\n",
        "Thank you for providing the starting snippet of the response! Since the response does not start with <rss>, it indicates that the structure is different, likely closer to a standard XML or HTML document. Based on this, letâ€™s adjust the tutorial and code to handle this new structure.\n",
        "\n",
        "Updated Approach for Parsing Response\n",
        "From the snippet, the response appears to start with an HTML structure, possibly containing <head> and <body> elements, along with the <title> and other metadata. This might still embed useful data but needs additional parsing logic."
      ],
      "metadata": {
        "id": "ADodzrQeoDfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(base_url, params=params)\n",
        "print(response.text)  # Print the full response to understand the structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-YjxPu1oZtJ",
        "outputId": "5b9207e0-2556-4fe6-a2f6-55e014bd2e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
            "  <head profile=\"http://a9.com/-/spec/opensearch/1.1/\">\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\"/>\n",
            "    <title>UNT Digital Library</title>\n",
            "    <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"https://digital.library.unt.edu/search/opensearch/document/\" title=\"UNT Digital Library\"/>\n",
            "    <link rel=\"alternate\" type=\"application/atom+xml\" href=\"https://digital.library.unt.edu/search/opensearch/?q=machine learning&amp;pw=1&amp;format=atom\"/>\n",
            "    <meta name=\"totalResults\" content=\"18095\"/>\n",
            "    <meta name=\"startIndex\" content=\"1\"/>\n",
            "    <meta name=\"itemsPerPage\" content=\"10\"/>\n",
            "  </head>\n",
            "  <body>\n",
            "    <ul>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944346/\">Machine Learning in Computational Chemistry</a>\n",
            "        <div>Machine learning and artificial intelligence are increasingly becoming mainstream in our daily lives, from smart algorithms that recognize us online to cars that can drive themselves.  In this defense, the intersection of machine learning and computational chemistry are applied to the generation of new PFAS molecules that are less toxic than those currently used today without sacrificing the unique properties that make them desirable for industrial use.  Additionally, machine learning is used to complete the SAMPL6 logP challenge and to correlate molecules to best DFT functionals for enthalpies of formation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1703277/\">Privacy Preserving Machine Learning as a Service</a>\n",
            "        <div>Machine learning algorithms based on neural networks have achieved remarkable results and are being extensively used in different domains. However, the machine learning algorithms requires access to raw data which is often privacy sensitive. To address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. In this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. We focus on training and classification of the well-known neural networks and convolutional neural networks. First, we design methods for approximation of the activation functions commonly used in CNNs (i.e. ReLU, Sigmoid, and Tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. Then, we train neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. Finally, we implement neural networks and convolutional neural networks over encrypted data and measure performance of the models.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc278720/\">A Machine Learning Method Suitable for Dynamic Domains</a>\n",
            "        <div>The efficacy of a machine learning technique is domain dependent. Some machine learning techniques work very well for certain domains but are ill-suited for other domains. One area that is of real-world concern is the flexibility with which machine learning techniques can adapt to dynamic domains. Currently, there are no known reports of any system that can learn dynamic domains, short of starting over (i.e., re-running the program). Starting over is neither time nor cost efficient for real-world production environments. This dissertation studied a method, referred to as Experience Based Learning (EBL), that attempts to deal with conditions related to learning dynamic domains. EBL is an extension of Instance Based Learning methods. The hypothesis of the study related to this research was that the EBL method would automatically adjust to domain changes and still provide classification accuracy similar to methods that require starting over. To test this hypothesis, twelve widely studied machine learning datasets were used. A dynamic domain was simulated by presenting these datasets in an uninterrupted cycle of train, test, and retrain. The order of the twelve datasets and the order of records within each dataset were randomized to control for order biases in each of ten runs. As a result, these methods provided datasets that represent extreme levels of domain change. Using the above datasets, EBL's mean classification accuracies for each dataset were compared to the published static domain results of other machine learning systems. The results indicated that the EBL's system performance was not statistically different (p&gt;0.30) from the other machine learning methods. These results indicate that the EBL system is able to adjust to an extreme level of domain change and yet produce satisfactory results. This finding supports the use of the EBL method in real-world environments that incur rapid changes to both variables and values.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc993374/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>This paper explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc990997/\">A Machine Learning Approach to Evaluating Translation Quality</a>\n",
            "        <div>Poster presented at the 2017 ACM/IEEE-CS Joint Conference on Digital Libraries. explores the possibility of applying Machine Learning for Machine Translation evaluation.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289519/\">Enterprise Use of Artificial Intelligence and Machine Learning</a>\n",
            "        <div>The objective of this report was to provide information on risks associated with Enterprise use of artificial intelligence and machine learning. The authors reviewed internal FHFA and Enterprise documents, as well as publicly available documents.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc2289499/\">Artificial Intelligence and Machine Learning In Consumer Products</a>\n",
            "        <div>This report provides background information on artificial intelligence and machine learning (AI/ML) and outlines a proposed framework to evaluate the safety of these technologies in consumer products. It outlines efforts underway and recommended future actions the CPSC can take to identify safety concerns with AI/ML technologies.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944318/\">Data Quality Evaluation and Improvement for Machine Learning</a>\n",
            "        <div>In this research the focus is on data-centric AI with a specific concentration on data quality evaluation and improvement for machine learning. We first present a practical framework for data quality evaluation and improvement, using a legal domain as a case study and build a corpus for legal argument mining. We first created an initial corpus with 4,937 instances that were manually labeled. We define five data quality evaluation dimensions: comprehensiveness, correctness, variety, class imbalance, and duplication, and conducted a quantitative evaluation on these dimensions for the legal dataset and two existing datasets in the medical domain for medical concept normalization. The first group of experiments showed that class imbalance and insufficient training data are the two major data quality issues that negatively impacted the quality of the system that was built on the legal corpus. The second group of experiments showed that the overlap between the test datasets and the training datasets, which we defined as \"duplication,\" is the major data quality issue for the two medical corpora. We explore several widely used machine learning methods for data quality improvement. Compared to pseudo-labeling, co-training, and expectation-maximization (EM), generative adversarial network (GAN) is more effective for automated data augmentation, especially when a small portion of labeled data and a large amount of unlabeled data is available. The data validation process, the performance improvement strategy, and the machine learning framework for data evaluation and improvement discussed in this dissertation can be used by machine learning researchers and practitioners to build high-performance machine learning systems. All the materials including the data, code, and results will be released at: https://github.com/haihua0913/dissertation-dqei.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1011752/\">Developing a Phylogeny Based Machine Learning Algorithm for Metagenomics</a>\n",
            "        <div>Metagenomics is the study of the totality of the complete genetic elements discovered from a defined environment. Different from traditional microbiology study, which only analyzes a small percent of microbes that could survive in laboratory, metagenomics allows researchers to get entire genetic information from all the samples in the communities. So metagenomics enables understanding of the target environments and the hidden relationships between bacteria and diseases. In order to efficiently analyze the metagenomics data, cutting-edge technologies for analyzing the relationships among microbes and communities are required. To overcome the challenges brought by rapid growth in metagenomics datasets, advances in novel methodologies for interpreting metagenomics data are clearly needed.\n",
            "The first two chapters of this dissertation summarize and compare the widely-used methods in metagenomics and integrate these methods into pipelines. Properly analyzing metagenomics data requires a variety of bioinformatcis and statistical approaches to deal with different situations. The raw reads from sequencing centers need to be processed and denoised by several steps and then be further interpreted by ecological and statistical analysis. So understanding these algorithms and combining different approaches could potentially reduce the influence of noises and biases at different steps. And an efficient and accurate pipeline is important to robustly decipher the differences and functionality of bacteria in communities.\n",
            "Traditional statistical analysis and machine learning algorithms have their limitations on analyzing metagenomics data. Thus, rest three chapters describe a new phylogeny based machine learning and feature selection algorithm to overcome these problems. The new method outperforms traditional algorithms and can provide more robust candidate microbes for further analysis. With the frowing sample size, deep neural network could potentially describe more complicated characteristic of data and thus improve model accuracy. So a deep learning framework is designed on top of the shallow learning algorithm stated above in order to further improve the prediction and selection accuracy.\n",
            "The present dissertation work provides a powerful tool that utilizes machine learning techniques to identify signature bacteria and key information from huge amount of metagenomics data.</div>\n",
            "      </li>\n",
            "      <li>\n",
            "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc897226/\">Coordinated machine learning and decision support for situation awareness.</a>\n",
            "        <div>For applications such as force protection, an effective decision maker needs to maintain an unambiguous grasp of the environment. Opportunities exist to leverage computational mechanisms for the adaptive fusion of diverse information sources. The current research employs neural networks and Markov chains to process information from sources including sensors, weather data, and law enforcement. Furthermore, the system operator's input is used as a point of reference for the machine learning algorithms. More detailed features of the approach are provided, along with an example force protection scenario.</div>\n",
            "      </li>\n",
            "    </ul>\n",
            "  </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://digital.library.unt.edu/search/opensearch/\"\n",
        "\n",
        "# Parameters for the query\n",
        "params = {\n",
        "    \"q\": \"machine learning\",  # Search term\n",
        "    \"type\": \"article\",        # Content type\n",
        "    \"start\": 0,               # Start index for pagination\n",
        "    \"rows\": 10                # Number of results per page\n",
        "}\n",
        "\n",
        "# Fetch data from the API\n",
        "response = requests.get(base_url, params=params)\n",
        "if response.status_code == 200:\n",
        "    # Parse as HTML\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Find relevant data\n",
        "    articles = []\n",
        "    for item in soup.find_all(\"item\"):  # Replace \"item\" with the correct tag if needed\n",
        "        title = item.find(\"title\").text if item.find(\"title\") else \"No title\"\n",
        "        link = item.find(\"link\").text if item.find(\"link\") else \"No link\"\n",
        "        description = item.find(\"description\").text if item.find(\"description\") else \"No description\"\n",
        "        articles.append({\"Title\": title, \"Link\": link, \"Description\": description})\n",
        "\n",
        "    # Convert to DataFrame and save to CSV\n",
        "    df = pd.DataFrame(articles)\n",
        "    if not df.empty:\n",
        "        df.to_csv(\"unt_articles.csv\", index=False)\n",
        "        print(\"Data saved to unt_articles.csv\")\n",
        "    else:\n",
        "        print(\"No articles found in the response.\")\n",
        "else:\n",
        "    print(f\"Failed to fetch data: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53fLpwXDok-K",
        "outputId": "db5aedc4-474d-4b6f-99be-c2f428ec1fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No articles found in the response.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***After couple of tries, with help of CHATGPT I found the cause and solved it. Below is the Final response***"
      ],
      "metadata": {
        "id": "Jce6_kzWom_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROMPT:**\n",
        "\n",
        "body>\n",
        "      <li>\n",
        "        <a href=\"https://digital.library.unt.edu/ark:/67531/metadc1944346/\">Machine Learning in Computational Chemistry</a>\n",
        "        <div>Machine learning and artificial intelligence are increasingly becoming mainstream in our daily lives, from smart algorithms that recognize us online to cars that can drive themselves.  In this defense, the intersection of machine learning and computational chemistry are applied to the generation of new PFAS molecules that are less toxic than those currently used today without sacrificing the unique properties that make them desirable for industrial use.  Additionally, machine learning is used to complete the SAMPL6 logP challenge and to correlate molecules to best DFT functionals for enthalpies of formation.</div>\n",
        "      </li>\n",
        "      <li>\n",
        "\n",
        "here is the example of the response"
      ],
      "metadata": {
        "id": "G97spR1JtXlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FINAL RESPONSE**\n"
      ],
      "metadata": {
        "id": "FMrioQ2F18Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rom bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://digital.library.unt.edu/search/opensearch/\"\n",
        "\n",
        "# Parameters for the query\n",
        "params = {\n",
        "    \"q\": \"machine learning\",  # Search term\n",
        "    \"type\": \"article\",        # Content type\n",
        "    \"start\": 0,               # Start index for pagination\n",
        "    \"rows\": 10                # Number of results per page\n",
        "}\n",
        "\n",
        "# Fetch data from the API\n",
        "response = requests.get(base_url, params=params)\n",
        "if response.status_code == 200:\n",
        "    # Parse as HTML\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Extract data from <li> elements\n",
        "    articles = []\n",
        "    for li in soup.find_all(\"li\"):\n",
        "        # Extract title and link\n",
        "        a_tag = li.find(\"a\")\n",
        "        title = a_tag.text if a_tag else \"No title\"\n",
        "        link = a_tag[\"href\"] if a_tag and \"href\" in a_tag.attrs else \"No link\"\n",
        "\n",
        "        # Extract description\n",
        "        description_div = li.find(\"div\")\n",
        "        description = description_div.text if description_div else \"No description\"\n",
        "\n",
        "        # Append the data to the list\n",
        "        articles.append({\"Title\": title, \"Link\": link, \"Description\": description})\n",
        "\n",
        "    # Convert to DataFrame and save to CSV\n",
        "    if articles:\n",
        "        df = pd.DataFrame(articles)\n",
        "        df.to_csv(\"unt_articles.csv\", index=False)\n",
        "        print(\"Data saved to unt_articles.csv\")\n",
        "    else:\n",
        "        print(\"No articles found in the response.\")\n",
        "else:\n",
        "    print(f\"Failed to fetch data: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfZ9i4NnpFC5",
        "outputId": "e2252409-9be5-4ad8-a2d6-8a0644ec77b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to unt_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#optional\n",
        "**For future response you can add your GPT chat history here**"
      ],
      "metadata": {
        "id": "7KIjgrffo58b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://chatgpt.com/share/6797bb89-ac88-800b-9342-edd79487582a"
      ],
      "metadata": {
        "id": "AXNGMLTcqoIj"
      }
    }
  ]
}